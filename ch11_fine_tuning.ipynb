{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4bd0e95-f15a-4b54-b56b-680956d94bbe",
   "metadata": {},
   "source": [
    "- 画像分類の事前学習済みモデルはすべて224*224画素の画像で学習済\n",
    "\n",
    "# ファインチューニングと転移学習\n",
    "- ファインチューニングは、学習済モデルのパラメタを初期値として利用するが、すべてのレイヤーで再学習する\n",
    "    - 学習データが大量にある場合に向いている → CIFAR10は5万件もあるので本章ではファインチューニングを用いる\n",
    "- 転移学習は、学習済モデルのパラメタのうち、入力に近い部分は固定し、出力に近い部分のみ学習する\n",
    "    - 学習データが少ない場合に向いている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bed8239-423a-4ee5-bfff-984f9659aa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要ライブラリのインポート\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a664455-8fc6-43ac-8cc4-570d8384b6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch関連ライブラリのインポート\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "from torchviz import make_dot\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c321fc29-8dfc-4cf4-a75c-d2fa00edba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warning表示off\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# デフォルトフォントサイズ変更\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "# デフォルトグラフサイズ変更\n",
    "plt.rcParams['figure.figsize'] = (6,6)\n",
    "\n",
    "# デフォルトで方眼表示ON\n",
    "plt.rcParams['axes.grid'] = True\n",
    "\n",
    "# numpyの表示桁数設定\n",
    "np.set_printoptions(suppress=True, precision=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7415cab1-cf90-4093-85fa-0c8f907418e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# GPUチェック\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87d1f0dd-f457-49e9-9309-9d52a1a7ff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 著者の共通関数読み込み\n",
    "import sys\n",
    "sys.path.append(\"../../lib/\")\n",
    "from pythonlibs.torch_lib1 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1699b6-3e70-414f-b67d-c25b2061c1c8",
   "metadata": {},
   "source": [
    "# 11.4 nn.AdaptiveAvgPool2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028d029e-e93c-4259-85f5-7cd84d95614d",
   "metadata": {},
   "source": [
    "- AdaptiveXXXPool2d で指定するパラメタは、変換後の画素数\n",
    "- 集約化の方法はXXXで決まる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f673f626-ebf0-409b-8dc9-6f4e2cf402cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "Linear(in_features=32, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "p = nn.AdaptiveAvgPool2d((1, 1))\n",
    "print(p)\n",
    "\n",
    "l1 = nn.Linear(32, 10)\n",
    "print(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58a3af6a-b705-45c9-8f9e-e8a140497d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 32, 1, 1])\n",
      "torch.Size([100, 32])\n",
      "torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "# 事前学習済みモデルのシミュレーション\n",
    "# 100枚 * 32チャネル * 16画素 * 16画素\n",
    "inputs = torch.randn(100, 32, 16, 16)\n",
    "m1 = p(inputs)\n",
    "m2 = m1.view(m1.shape[0], -1)\n",
    "m3 = l1(m2)\n",
    "\n",
    "# チャネルごとに平均値の1画素のみとなる\n",
    "print(m1.shape)\n",
    "# 画像ごとに一次元ベクトル化\n",
    "print(m2.shape)\n",
    "print(m3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539ed8e0-a755-42c4-a74a-cc69e428518d",
   "metadata": {},
   "source": [
    "- この仕組みで、inputsのshapeが[100, 32, 8, 8]でも[100, 32, 4, 4]でも、同じ線形関数 Linear(32, 10) で受け取れる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a80694-4a45-492c-b045-816034bb6c9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
